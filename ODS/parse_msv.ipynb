{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b4b5991",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, shutil, os, sys, shlex, subprocess\n",
    "from pandas import DataFrame, read_excel\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.impute import SimpleImputer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from imblearn.pipeline import make_pipeline as imbalanced_make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold, learning_curve\n",
    "from sklearn import svm\n",
    "from sklearn.utils import shuffle\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7602d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "msv_results_path = \"\"\n",
    "\n",
    "def mkdir(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "def get_plausible_results(msv_results_path):\n",
    "    mkdir(f\"{msv_results_path}-parsed\")\n",
    "    for directory in os.listdir(msv_results_path):\n",
    "        if not directory.endswith(\"50\"):\n",
    "            continue\n",
    "\n",
    "        plausibles = []\n",
    "        with open(f\"{msv_results_path}/{directory}/msv-original-sim-data.json\") as f:\n",
    "            history = json.load(f)\n",
    "            for patch in history.keys():\n",
    "                if history[patch][\"plausible\"]:\n",
    "                    plausibles.append({patch: history[patch]})\n",
    "\n",
    "        with open(f\"{msv_results_path}-parsed/{directory}.json\", \"w+\") as f:\n",
    "            json.dump(plausibles, f)\n",
    "    \n",
    "def copy_patches(msv_results_path_parsed, patch_results_path):\n",
    "    for project in os.listdir(msv_results_path_parsed):\n",
    "        project_name = project.split(\"-\")[0]\n",
    "        candidates = json.load(open(f\"{msv_results_path_parsed}/{project}\"))\n",
    "\n",
    "        if project_name not in os.listdir(patch_results_path):\n",
    "            continue\n",
    "            \n",
    "        mkdir(f\"plausible_patches/{project_name}\")\n",
    "\n",
    "        for candidate in candidates:\n",
    "            path = next(iter(candidate.keys()))\n",
    "            path = path.split(\"/\")[1]\n",
    "\n",
    "            for patch in os.listdir(f\"{patch_results_path}/{project_name}\"):\n",
    "                if patch != path:\n",
    "                    continue\n",
    "                shutil.copyfile(f\"{patch_results_path}/{project_name}/{patch}\", \n",
    "                           f\"plausible_patches/{project_name}/{patch}\")\n",
    "                \n",
    "def parse_for_coming():\n",
    "    for project in os.listdir(\"plausible_patches/\"):\n",
    "        for idx in os.listdir(f\"plausible_patches/{project}\"):\n",
    "            diff_folder = project + \"-\" + idx[:idx.rfind(\"_\")].replace(\"_\", \"-\")\n",
    "\n",
    "            file = os.listdir(f\"plausible_patches/{project}/{idx}\")[0]\n",
    "            modif_file = os.listdir(f\"plausible_patches/{project}/{idx}\")[0].split(\".\")[0]\n",
    "            \n",
    "            mkdir(f\"coming_rep/{diff_folder}/{modif_file}\")\n",
    "\n",
    "            shutil.copyfile(f\"plausible_patches/{project}/{idx}/{file}\", \n",
    "                            f\"coming_rep/{diff_folder}/{modif_file}/{diff_folder}_{modif_file}_t.java\")\n",
    "            \n",
    "def get_src_path(project):\n",
    "    project_name, bug_id = project.split(\"_\")\n",
    "    bug_id = int(bug_id)\n",
    "    if project_name == \"Math\":\n",
    "        if bug_id < 85:\n",
    "            return \"/src/main/java/\"\n",
    "        return \"/src/java/\"\n",
    "    elif project_name == \"Time\":\n",
    "        return \"/src/main/java/\"\n",
    "    elif project_name == \"Lang\":\n",
    "        if bug_id <= 35: \n",
    "            return \"/src/main/java/\"\n",
    "        return \"/src/java/\"\n",
    "    elif project_name == \"Chart\":\n",
    "        return \"/source/\"\n",
    "    elif project_name == \"Closure\":\n",
    "        return \"/src/\"\n",
    "    elif project_name == \"Mockito\":\n",
    "        return \"/src/\"\n",
    "    return None\n",
    "\n",
    "def fetch_buggy_files(buggy_projects_path):\n",
    "    for project in os.listdir(\"coming_rep/\"):\n",
    "        project_name = project.split(\"-\")[0]\n",
    "        src_path = get_src_path(project_name)\n",
    "        src_file = os.listdir(f\"coming_rep/{project}\")[0]\n",
    "        target_file = os.listdir(f\"coming_rep/{project}/{src_file}\")[0]\n",
    "\n",
    "        mid_path = None\n",
    "        with open(f\"coming_rep/{project}/{src_file}/{target_file}\") as f:\n",
    "            for line in f.readlines():\n",
    "                if line.startswith(\"package \"):\n",
    "                    mid_path = line[8:].strip()[:-1].replace(\".\", \"/\")\n",
    "                    break\n",
    "\n",
    "        if mid_path is None:\n",
    "            print(\"Fail for\", project)\n",
    "            continue\n",
    "\n",
    "        buggy_file = f\"{buggy_projects_path}/{project_name}/{src_path}/{mid_path}/{src_file}.java\"\n",
    "\n",
    "        shutil.copyfile(buggy_file, f\"coming_rep/{project}/{src_file}/{project}_{src_file}_s.java\")\n",
    "        \n",
    "def parse_msv(msv_results_path, patch_results_path, buggy_projects_path):\n",
    "    get_plausible_results(msv_results_path)\n",
    "    msv_results_path_parsed = msv_results_path + \"-parsed\"\n",
    "    copy_patches(msv_results_path_parsed, patch_results_path)\n",
    "    parse_for_coming()\n",
    "    fetch_buggy_files(buggy_projects_path)\n",
    "    \n",
    "args = sys.argv\n",
    "msv_results_logs = args[1]\n",
    "generated_patches_path = args[2]\n",
    "path_to_buggy_projects = args[3]\n",
    "parse_msv(msv_results_logs, generated_patches_path, path_to_buggy_projects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f6a9976",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run Coming tool\n",
    "def run_coming(coming_path, pairs_path):\n",
    "    command = f\"java -classpath {coming_path}/target/coming-0-SNAPSHOT-jar-with-dependencies.jar fr.inria.coming.main.ComingMain -input files -mode features -location {pairs_path} -output ./out\"\n",
    "    process = subprocess.Popen(shlex.split(command), stderr=subprocess.PIPE, stdout=subprocess.PIPE)\n",
    "    stdout, stderr = process.communicate()\n",
    "    \n",
    "    if process.returncode != 0:\n",
    "        print(stderr)\n",
    "        raise Exception(\"Something wrong with Coming\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee390460",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ods():\n",
    "    training_list= \"./train.csv\"\n",
    "    testing_list= \"./test.csv\"\n",
    "\n",
    "    training = pd.read_csv(training_list, encoding='latin1',index_col=False)\n",
    "    testing = pd.read_csv(testing_list, encoding='latin1',index_col=False)\n",
    "\n",
    "    X_train = training.iloc[:,2:]\n",
    "    Y_train = training.iloc[:,1]\n",
    "    X_test = testing.iloc[:,1:]\n",
    "    id_test = testing.iloc[:,0]\n",
    "\n",
    "    X_train, Y_train = shuffle(X_train, Y_train, random_state=0)\n",
    "    X_train, Y_train = X_train.values, Y_train.values\n",
    "    model = xgb.XGBClassifier(random_state=42, max_depth=6, gamma=0.5)\n",
    "    eval_set=[(X_train,Y_train)]\n",
    "    model.fit(X_train,Y_train, early_stopping_rounds=30, eval_metric=\"mae\", eval_set=eval_set)\n",
    "    Y_pred = model.predict_proba(X_test)[:, 1]\n",
    "    result={'patch':id_test,'prediction_label':Y_pred}\n",
    "    resultDF = pd.DataFrame(result)\n",
    "    resultDF.to_csv('./prediction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f82d378",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ods",
   "language": "python",
   "name": "ods"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
